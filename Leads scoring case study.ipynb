{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d324907",
   "metadata": {},
   "source": [
    "# Leads scoring case study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61e46e2",
   "metadata": {},
   "source": [
    "##### Problem Statement\n",
    "\n",
    "An education company named X Education sells online courses to industry professionals. On any given day, many professionals who are interested in the courses land on their website and browse for courses. \n",
    "\n",
    " \n",
    "\n",
    "The company markets its courses on several websites and search engines like Google. Once these people land on the website, they might browse the courses or fill up a form for the course or watch some videos. When these people fill up a form providing their email address or phone number, they are classified to be a lead. Moreover, the company also gets leads through past referrals. Once these leads are acquired, employees from the sales team start making calls, writing emails, etc. Through this process, some of the leads get converted while most do not. The typical lead conversion rate at X education is around 30%. \n",
    "\n",
    " \n",
    "\n",
    "Now, although X Education gets a lot of leads, its lead conversion rate is very poor. For example, if, say, they acquire 100 leads in a day, only about 30 of them are converted. To make this process more efficient, the company wishes to identify the most potential leads, also known as ‘Hot Leads’. If they successfully identify this set of leads, the lead conversion rate should go up as the sales team will now be focusing more on communicating with the potential leads rather than making calls to everyone. A typical lead conversion process can be represented using the following funnel:\n",
    "\n",
    "Lead Conversion Process - Demonstrated as a funnel\n",
    "Lead Conversion Process - Demonstrated as a funnel\n",
    "As you can see, there are a lot of leads generated in the initial stage (top) but only a few of them come out as paying customers from the bottom. In the middle stage, you need to nurture the potential leads well (i.e. educating the leads about the product, constantly communicating etc. ) in order to get a higher lead conversion.\n",
    "\n",
    " \n",
    "\n",
    "X Education has appointed you to help them select the most promising leads, i.e. the leads that are most likely to convert into paying customers. The company requires you to build a model wherein you need to assign a lead score to each of the leads such that the customers with a higher lead score have a higher conversion chance and the customers with a lower lead score have a lower conversion chance. The CEO, in particular, has given a ballpark of the target lead conversion rate to be around 80%.\n",
    "\n",
    "\n",
    "##### Goals of the Case Study\n",
    "\n",
    "Build a logistic regression model to assign a lead score between 0 and 100 to each of the leads which can be used by the company to target potential leads. A higher score would mean that the lead is hot, i.e. is most likely to convert whereas a lower score would mean that the lead is cold and will mostly not get converted.\n",
    "\n",
    "There are some more problems presented by the company which your model should be able to adjust to if the company's requirement changes in the future so you will need to handle these as well. These problems are provided in a separate doc file. Please fill it based on the logistic regression model you got in the first step. Also, make sure you include this in your final PPT where you'll make recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a14a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbe9345",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Leads.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#importing dataset\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m leads_df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLeads.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m leads_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Leads.csv'"
     ]
    }
   ],
   "source": [
    "#importing dataset\n",
    "\n",
    "leads_df=pd.read_csv(\"Leads.csv\")\n",
    "leads_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9dd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48782db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d30fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d286d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0c0def",
   "metadata": {},
   "source": [
    "### EXPLORATORY DATA ANALYSIS\n",
    "### Data understanding, preparation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicates\n",
    "\n",
    "sum(leads_df.duplicated(subset = 'Prospect ID')) == 0\n",
    "sum(leads_df.duplicated(subset = 'Lead Number')) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563b6fc",
   "metadata": {},
   "source": [
    "No duplicate values found in Prospect ID & Lead Number in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d1500",
   "metadata": {},
   "source": [
    "\n",
    "Prospect ID & Lead Number are two variables that are just indicative of the ID number of the approched People so can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c0b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping Lead Number and Prospect ID since they have all unique values\n",
    "\n",
    "leads_df.drop(['Prospect ID', 'Lead Number'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting 'Select' values to NaN.\n",
    "\n",
    "leads_df = leads_df.replace('Select', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking null values in each rows\n",
    "\n",
    "leads_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74729517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking percentage of null values in each column\n",
    "\n",
    "round(100*(leads_df.isnull().sum()/len(leads_df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping cols with more than 45% missing values\n",
    "\n",
    "cols=leads_df.columns\n",
    "\n",
    "for i in cols:\n",
    "    if((100*(leads_df[i].isnull().sum()/len(leads_df.index))) >= 45):\n",
    "        leads_df.drop(i, 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking null values percentage\n",
    "\n",
    "round(100*(leads_df.isnull().sum()/len(leads_df.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91d1d9",
   "metadata": {},
   "source": [
    "##### Categorical Varaible Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c111be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts of Country column\n",
    "\n",
    "leads_df['Country'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f5b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting spread of Country columnn \n",
    "plt.figure(figsize=(10,5))\n",
    "s1=sns.countplot(leads_df.Country, hue=leads_df.Converted)\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3cdf30",
   "metadata": {},
   "source": [
    "As we can see the Number of Values for India are quite high, so this column can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of columns to be droppped\n",
    "\n",
    "cols_to_drop=['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f2a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts of \"City\" column\n",
    "\n",
    "leads_df['City'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf651c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['City'] = leads_df['City'].replace(np.nan,'Mumbai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3360ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting spread of City columnn after replacing NaN values\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "s1=sns.countplot(leads_df.City, hue=leads_df.Converted)\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts of Specialization column\n",
    "\n",
    "leads_df['Specialization'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75554a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead may not have mentioned specialization because it was not in the list or maybe they are a students \n",
    "# and don't have a specialization yet. So we will replace NaN values here with 'Not Specified'\n",
    "\n",
    "leads_df['Specialization'] = leads_df['Specialization'].replace(np.nan, 'Not Specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ecaa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting spread of Specialization columnn \n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "s1=sns.countplot(leads_df.Specialization, hue=leads_df.Converted)\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d9497",
   "metadata": {},
   "source": [
    "By the graph We see that specialization with Management are having higher number of leads as well as leads converted. So this is definitely a significant variable and should not be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb06819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining Management Specializations because they show similar trends\n",
    "\n",
    "leads_df['Specialization'] = leads_df['Specialization'].replace(['Finance Management','Human Resource Management',\n",
    "                                                           'Marketing Management','Operations Management',\n",
    "                                                           'IT Projects Management','Supply Chain Management',\n",
    "                                                    'Healthcare Management','Hospitality Management',\n",
    "                                                           'Retail Management'] ,'Management_Specializations')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing count of Variable based on Converted value\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "s1=sns.countplot(leads_df.Specialization, hue=leads_df.Converted)\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is your current occupation\n",
    "\n",
    "leads_df['What is your current occupation'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd12146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing Nan values with mode \"Unemployed\"\n",
    "\n",
    "leads_df['What is your current occupation'] = leads_df['What is your current occupation'].replace(np.nan, 'Unemployed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521cc9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking count of values\n",
    "leads_df['What is your current occupation'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf43b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing count of Variable based on Converted value\n",
    "s1=sns.countplot(leads_df['What is your current occupation'], hue=leads_df.Converted)\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37ad2f",
   "metadata": {},
   "source": [
    "Working Professionals going for the course have high chances of joining it.\n",
    "Unemployed leads are the most in terms of Absolute numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts\n",
    "\n",
    "leads_df['What matters most to you in choosing a course'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bed26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing Nan values with Mode \"Better Career Prospects\"\n",
    "\n",
    "leads_df['What matters most to you in choosing a course'] = leads_df['What matters most to you in choosing a course'].replace(np.nan,'Better Career Prospects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e928d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing count of Variable based on Converted value\n",
    "\n",
    "s1=sns.countplot(leads_df['What matters most to you in choosing a course'], hue=leads_df.Converted)\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dada2ec",
   "metadata": {},
   "source": [
    "this variable will not impact the data because it does not have significant meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae60a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts of variable\n",
    "leads_df['What matters most to you in choosing a course'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7026af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here again we have another Column that is worth Dropping. So we Append to the cols_to_drop List\n",
    "cols_to_drop.append('What matters most to you in choosing a course')\n",
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48615945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts of Tag variable\n",
    "leads_df['Tags'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing Nan values with \"Not Specified\"\n",
    "leads_df['Tags'] = leads_df['Tags'].replace(np.nan,'Not Specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing count of Variable based on Converted value\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "s1=sns.countplot(leads_df['Tags'], hue=leads_df.Converted)\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebfef4",
   "metadata": {},
   "source": [
    "some of the tags are with very low frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1af03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing tags with low frequency with \"Other Tags\"\n",
    "leads_df['Tags'] = leads_df['Tags'].replace(['In confusion whether part time or DLP', 'in touch with EINS','Diploma holder (Not Eligible)',\n",
    "                                     'Approached upfront','Graduation in progress','number not provided', 'opp hangup','Still Thinking',\n",
    "                                    'Lost to Others','Shall take in the next coming month','Lateral student','Interested in Next batch',\n",
    "                                    'Recognition issue (DEC approval)','Want to take admission but has financial problems',\n",
    "                                    'University not recognized'], 'Other_Tags')\n",
    "\n",
    "leads_df['Tags'] = leads_df['Tags'].replace(['switched off',\n",
    "                                      'Already a student',\n",
    "                                       'Not doing further education',\n",
    "                                       'invalid number',\n",
    "                                       'wrong number given',\n",
    "                                       'Interested  in full time MBA'] , 'Other_Tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4827eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking percentage of missing values\n",
    "round(100*(leads_df.isnull().sum()/len(leads_df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts of Lead Source column\n",
    "\n",
    "leads_df['Lead Source'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing Nan Values and combining low frequency values\n",
    "leads_df['Lead Source'] = leads_df['Lead Source'].replace(np.nan,'Others')\n",
    "leads_df['Lead Source'] = leads_df['Lead Source'].replace('google','Google')\n",
    "leads_df['Lead Source'] = leads_df['Lead Source'].replace('Facebook','Social Media')\n",
    "leads_df['Lead Source'] = leads_df['Lead Source'].replace(['bing','Click2call','Press_Release',\n",
    "                                                     'youtubechannel','welearnblog_Home',\n",
    "                                                     'WeLearn','blog','Pay per Click Ads',\n",
    "                                                    'testone','NC_EDM'] ,'Others') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20803396",
   "metadata": {},
   "source": [
    "We can group some of the lower frequency occuring labels under a common label 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing count of Variable based on Converted value\n",
    "plt.figure(figsize=(15,5))\n",
    "s1=sns.countplot(leads_df['Lead Source'], hue=leads_df.Converted)\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e62c171",
   "metadata": {},
   "source": [
    "Obsevations from the graph\n",
    "1. Maximum number of leads are generated by Google and Direct traffic.\n",
    "2. Conversion Rate of reference leads and leads through welingak website is high.\n",
    "3. To improve overall lead conversion rate, focus should be on improving lead converion of olark chat, organic search, direct traffic, and google leads and generate more leads from reference and welingak website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7772f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lead Origin\n",
    "leads_df['Lead Origin'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing count of Variable based on Converted value\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "s1=sns.countplot(leads_df['Lead Origin'], hue=leads_df.Converted)\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dfa130",
   "metadata": {},
   "source": [
    "Observaions\n",
    "\n",
    "1. API and Landing Page Submission bring higher number of leads as well as conversion.\n",
    "2. Lead Add Form has a very high conversion rate but count of leads are not very high.\n",
    "3. Lead Import and Quick Add Form get very few leads.\n",
    "4. In order to improve overall lead conversion rate, we have to improve lead converion of API and Landing Page Submission origin and generate more leads from Lead Add Form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.subplots(figsize=(16, 16))\n",
    "\n",
    "for i, feature in enumerate(['Lead Source', 'Lead Origin']):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.subplots_adjust(hspace = 6.0)\n",
    "    sns.countplot(x=feature, hue=\"Converted\",data=leads_df)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f3091",
   "metadata": {},
   "source": [
    "**OBSERVATION:**\n",
    "- Despite having a relatively lower conversion rate of approximately 30%, both API and Landing Page Submission generate a substantial number of leads.\n",
    "- Conversely, the Lead Add Form generates a significantly lower count of leads, yet boasts a notably high conversion rate.\n",
    "- Lead Import contributes negligibly to both lead count and conversion rate and can be disregarded.\n",
    "- To enhance the overall lead conversion rate, efforts should be directed towards improving the conversion rates of API and Landing Page Submission, while simultaneously increasing lead generation.Form'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last Activity:\n",
    "\n",
    "leads_df['Last Activity'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Last Activity\", hue=\"Converted\", data= leads_df)\n",
    "plt.xticks( rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e463c62",
   "metadata": {},
   "source": [
    "**OBSERVATION:**\n",
    "\n",
    "- The highest count among last activities is recorded for \"Email Opened\".\n",
    "- \n",
    "The maximum conversion rate is observed for the last activity being \"SMS Sent\".\n",
    "\n",
    "**We should focus on increasing the conversion rate of those having last activity as Email Opened by making a call to those leads and also try to increase the count of the ones having last activity as SMS sent**-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6266abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing Nan Values and combining low frequency values\n",
    "\n",
    "leads_df['Last Activity'] = leads_df['Last Activity'].replace(np.nan,'Others')\n",
    "leads_df['Last Activity'] = leads_df['Last Activity'].replace(['Unreachable','Unsubscribed',\n",
    "                                                        'Had a Phone Conversation', \n",
    "                                                        'Approached upfront',\n",
    "                                                        'View in browser link Clicked',       \n",
    "                                                        'Email Marked Spam',                  \n",
    "                                                        'Email Received','Resubscribed to emails',\n",
    "                                                         'Visited Booth in Tradeshow'],'Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6206840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last Activity:\n",
    "\n",
    "leads_df['Last Activity'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the Null Values in All Columns:\n",
    "round(100*(leads_df.isnull().sum()/len(leads_df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251841f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all rows which have Nan Values. Since the number of Dropped rows is less than 2%, it will not affect the model\n",
    "leads_df = leads_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking percentage of Null Values in All Columns:\n",
    "round(100*(leads_df.isnull().sum()/len(leads_df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do Not Email & Do Not Call\n",
    "#visualizing count of Variable based on Converted value\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "ax1=plt.subplot(1, 2, 1)\n",
    "ax1=sns.countplot(leads_df['Do Not Call'], hue=leads_df.Converted)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\n",
    "\n",
    "ax2=plt.subplot(1, 2, 2)\n",
    "ax2=sns.countplot(leads_df['Do Not Email'], hue=leads_df.Converted)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts for Do Not Call\n",
    "leads_df['Do Not Call'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts for Do Not Email\n",
    "leads_df['Do Not Email'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007464c0",
   "metadata": {},
   "source": [
    "We Can append the Do Not Call Column to the list of Columns to be Dropped since > 90% is of only one Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop.append('Do Not Call')\n",
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11caf7",
   "metadata": {},
   "source": [
    "IMBALANCED VARIABLES THAT CAN BE DROPPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b41578",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.Search.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f52f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.Magazine.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e889719",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['Newspaper Article'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['X Education Forums'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['Newspaper'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['Digital Advertisement'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bbc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['Through Recommendations'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['Receive More Updates About Our Courses'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a91059",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['Update me on Supply Chain Content'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['Get updates on DM Content'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['I agree to pay the amount through cheque'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ae769",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['A free copy of Mastering The Interview'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding imbalanced columns to the list of columns to be dropped\n",
    "\n",
    "cols_to_drop.extend(['Search','Magazine','Newspaper Article','X Education Forums','Newspaper',\n",
    "                 'Digital Advertisement','Through Recommendations','Receive More Updates About Our Courses',\n",
    "                 'Update me on Supply Chain Content',\n",
    "                 'Get updates on DM Content','I agree to pay the amount through cheque'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5096f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts of last Notable Activity\n",
    "leads_df['Last Notable Activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720373f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clubbing lower frequency values\n",
    "leads_df['Last Notable Activity'] = leads_df['Last Notable Activity'].replace(['Had a Phone Conversation',\n",
    "                                                                       'Email Marked Spam',\n",
    "                                                                         'Unreachable',\n",
    "                                                                         'Unsubscribed',\n",
    "                                                                         'Email Bounced',                                                                    \n",
    "                                                                       'Resubscribed to emails',\n",
    "                                                                       'View in browser link Clicked',\n",
    "                                                                       'Approached upfront', \n",
    "                                                                       'Form Submitted on Website', \n",
    "                                                                       'Email Received'],'Other_Notable_activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd606178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing count of Variable based on Converted value\n",
    "\n",
    "plt.figure(figsize = (14,5))\n",
    "ax1=sns.countplot(x = \"Last Notable Activity\", hue = \"Converted\", data = leads_df)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts for variable\n",
    "\n",
    "leads_df['Last Notable Activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1024989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns to be dropped\n",
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc23742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns\n",
    "leads_df = leads_df.drop(cols_to_drop,1)\n",
    "leads_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b10b4f6",
   "metadata": {},
   "source": [
    "Some of the columns have been dropped as they are not impcat the data too much "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb989f0",
   "metadata": {},
   "source": [
    "##### EDA on Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the % of Data that has Converted Values = 1:\n",
    "\n",
    "Converted = (sum(leads_df['Converted'])/len(leads_df['Converted'].index))*100\n",
    "Converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf9f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking correlations of numeric values\n",
    "# figure size\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# heatmap\n",
    "sns.heatmap(leads_df.corr(), cmap=\"YlGnBu\", annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654e2fd",
   "metadata": {},
   "source": [
    "total time spent on variable is corelated to converted "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8454b2",
   "metadata": {},
   "source": [
    "For numerical variables we need to plot the boxplots t check the any outliers present in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Visits\n",
    "#visualizing spread of variable\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(y=leads_df['TotalVisits'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c540a174",
   "metadata": {},
   "source": [
    "From the boxplot we can see that there are more outliers in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking percentile values for \"Total Visits\"\n",
    "\n",
    "leads_df['TotalVisits'].describe(percentiles=[0.05,.25, .5, .75, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Treatment: Remove top & bottom 1% of the Column Outlier values\n",
    "\n",
    "Q3 = leads_df.TotalVisits.quantile(0.99)\n",
    "leads_df = leads_df[(leads_df.TotalVisits <= Q3)]\n",
    "Q1 = leads_df.TotalVisits.quantile(0.01)\n",
    "leads_df = leads_df[(leads_df.TotalVisits >= Q1)]\n",
    "sns.boxplot(y=leads_df['TotalVisits'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30deca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394cdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking percentiles for \"Total Time Spent on Website\"\n",
    "\n",
    "leads_df['Total Time Spent on Website'].describe(percentiles=[0.05,.25, .5, .75, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69140a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing spread of numeric variable\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(y=leads_df['Total Time Spent on Website'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49678cb7",
   "metadata": {},
   "source": [
    "Since there are no major Outliers for the above variable we don't do any Outlier Treatment for this above Column\n",
    "\n",
    "Check for Page Views Per Visit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking spread of \"Page Views Per Visit\"\n",
    "\n",
    "leads_df['Page Views Per Visit'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing spread of numeric variable\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(y=leads_df['Page Views Per Visit'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Treatment: Remove top & bottom 1% \n",
    "\n",
    "Q3 = leads_df['Page Views Per Visit'].quantile(0.99)\n",
    "leads_df = leads_df[leads_df['Page Views Per Visit'] <= Q3]\n",
    "Q1 = leads_df['Page Views Per Visit'].quantile(0.01)\n",
    "leads_df = leads_df[leads_df['Page Views Per Visit'] >= Q1]\n",
    "sns.boxplot(y=leads_df['Page Views Per Visit'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc526f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking Spread of \"Total Visits\" vs Converted variable\n",
    "sns.boxplot(y = 'TotalVisits', x = 'Converted', data = leads_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9902b93",
   "metadata": {},
   "source": [
    "Obsevations\n",
    "\n",
    "1. Median for converted and not converted leads are the close.\n",
    "2. Nothng conclusive can be said on the basis of Total Visits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3feda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking Spread of \"Total Time Spent on Website\" vs Converted variable\n",
    "\n",
    "sns.boxplot(x=leads_df.Converted, y=leads_df['Total Time Spent on Website'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e958c",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "1. Leads spending more time on the website are more likely to be converted.\n",
    "2. Website should be made more engaging to make leads spend more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking Spread of \"Page Views Per Visit\" vs Converted variable\n",
    "\n",
    "sns.boxplot(x=leads_df.Converted,y=leads_df['Page Views Per Visit'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50069f91",
   "metadata": {},
   "source": [
    "Observations\n",
    "\n",
    "1. Median for converted and unconverted leads is the same.\n",
    "2. Nothing can be said specifically for lead conversion from Page Views Per Visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df593d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking missing values in leftover columns/\n",
    "\n",
    "round(100*(leads_df.isnull().sum()/len(leads_df.index)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50483d50",
   "metadata": {},
   "source": [
    "There are no missing values in the columns to be analyzed further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af29d7f",
   "metadata": {},
   "source": [
    "##### Creating a dummy variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a list of categorical columns\n",
    "\n",
    "cat_cols= leads_df.select_dtypes(include=['object']).columns\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ec0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to map\n",
    "\n",
    "list =  ['A free copy of Mastering The Interview','Do Not Email']\n",
    "\n",
    "# Defining the map function\n",
    "def binary_map(x):\n",
    "    return x.map({'Yes': 1, \"No\": 0})\n",
    "\n",
    "# Applying the function to the housing list\n",
    "leads_df[list] = leads_df[list].apply(binary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe62006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting dummies and dropping the first column and adding the results to the master dataframe\n",
    "dummy = pd.get_dummies(leads_df[['Lead Origin','What is your current occupation',\n",
    "                             'City']], drop_first=True)\n",
    "\n",
    "leads_df = pd.concat([leads_df,dummy],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b20ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(leads_df['Specialization'], prefix  = 'Specialization')\n",
    "dummy = dummy.drop(['Specialization_Not Specified'], 1)\n",
    "leads_df = pd.concat([leads_df, dummy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e84eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(leads_df['Lead Source'], prefix  = 'Lead Source')\n",
    "dummy = dummy.drop(['Lead Source_Others'], 1)\n",
    "leads_df = pd.concat([leads_df, dummy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9348d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(leads_df['Last Activity'], prefix  = 'Last Activity')\n",
    "dummy = dummy.drop(['Last Activity_Others'], 1)\n",
    "leads_df = pd.concat([leads_df, dummy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca24f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(leads_df['Last Notable Activity'], prefix  = 'Last Notable Activity')\n",
    "dummy = dummy.drop(['Last Notable Activity_Other_Notable_activity'], 1)\n",
    "leads_df = pd.concat([leads_df, dummy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa125ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(leads_df['Tags'], prefix  = 'Tags')\n",
    "dummy = dummy.drop(['Tags_Not Specified'], 1)\n",
    "leads_df = pd.concat([leads_df, dummy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cbf065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the original columns after dummy variable creation\n",
    "\n",
    "leads_df.drop(cat_cols,1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f65657",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f5f623",
   "metadata": {},
   "source": [
    "###### To build the logistic regression model we will split the data into train set ata and test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f482314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Putting response variable to y\n",
    "y = leads_df['Converted']\n",
    "\n",
    "y.head()\n",
    "\n",
    "X=leads_df.drop('Converted', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ec356",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558741da",
   "metadata": {},
   "source": [
    "##### We will scale the data as the data will be irregular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb6d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling numeric columns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "num_cols=X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea0c1c",
   "metadata": {},
   "source": [
    "##### Model Building using Stats Model & RFE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae60a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73841715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 15)             # running RFE with 15 variables as output\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa03866",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of RFE supported columns\n",
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34533dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7ce25",
   "metadata": {},
   "source": [
    "We splitted the data into train data and test data now we will build the model and do the prediction on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce957014",
   "metadata": {},
   "source": [
    "# Logistic regression model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm1 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm1.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e32a39",
   "metadata": {},
   "source": [
    "from the first model we can see that the p value for the variable Lead Origin_Lead Add Form is more so we can drop that variable and again build the second model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping column with high p-value\n",
    "col = col.drop('Lead Origin_Lead Add Form',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d36e5e",
   "metadata": {},
   "source": [
    "# Logistic regression model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2615ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89be01c",
   "metadata": {},
   "source": [
    "from the second model we can see that the p value for the variable Tags_Closed by Horizzon is more so we can drop that variable and again build the third model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeb33b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping column with high p-value\n",
    "col = col.drop('Tags_Closed by Horizzon',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04371e9d",
   "metadata": {},
   "source": [
    "# Logistic regression model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1bdb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083667c2",
   "metadata": {},
   "source": [
    "p-value of variable Last Notable Activity_Modified is high, so we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping column with high p-value\n",
    "\n",
    "col = col.drop('Last Notable Activity_Modified',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051ef51",
   "metadata": {},
   "source": [
    "# Logistic regression model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c61e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96effd6a",
   "metadata": {},
   "source": [
    "p-value of variable Last Activity_Page Visited on Website is high  so we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52720afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping column with high p-value\n",
    "\n",
    "col = col.drop('Last Activity_Page Visited on Website',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2b6a4",
   "metadata": {},
   "source": [
    "# Logistic regression model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d6428",
   "metadata": {},
   "source": [
    "Since 'All' the p-values are less we can check the Variance Inflation Factor to see if there is any correlation between the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd559d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF values of the feature variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941979c",
   "metadata": {},
   "source": [
    "By the VIF we can see that the value is not more for all the variables So  Moving on to derive the Probabilities, Lead Score, Predictions on Train Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0ae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Predicted values on the train set\n",
    "y_train_pred = res.predict(X_train_sm)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_prob':y_train_pred})\n",
    "y_train_pred_final['Prospect ID'] = y_train.index\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d92e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['Predicted'] = y_train_pred_final.Converted_prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203eb80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Confusion matrix \n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bd9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.Predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0bec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edf0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate False Postive Rate - predicting conversion when customer does not have convert\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5afb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive predictive value \n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96e42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550b2ea0",
   "metadata": {},
   "source": [
    "##### PLOTTING ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31837003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Converted_prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bef4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Converted_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37c6b2",
   "metadata": {},
   "source": [
    "The ROC Curve should be a value close to 1. We are getting a good value of 0.97 indicating a good predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55521d77",
   "metadata": {},
   "source": [
    "##### Finding Optimal Cutoff Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dfdeda",
   "metadata": {},
   "source": [
    "Above we had chosen an arbitrary cut-off value of 0.5. We need to determine the best cut-off value and the below section deals with that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Converted_prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa8a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08349c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### From the curve above, 0.3 is the optimum point to take it as a cutoff probability.\n",
    "\n",
    "y_train_pred_final['final_Predicted'] = y_train_pred_final.Converted_prob.map( lambda x: 1 if x > 0.3 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['Lead_Score'] = y_train_pred_final.Converted_prob.map( lambda x: round(x*100))\n",
    "\n",
    "y_train_pred_final[['Converted','Converted_prob','Prospect ID','final_Predicted','Lead_Score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_Predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac92221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43db6335",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "So as we can see above the model seems to be performing well. The ROC curve has a value of 0.97, which is very good. We have the following values for the Train Data:\n",
    "\n",
    "\n",
    "Accuracy : 90.81%\n",
    "\n",
    "Sensitivity : 92.05%\n",
    "\n",
    "Specificity : 90.23%\n",
    "\n",
    "Some of the other Stats are derived below, indicating the False Positive Rate, Positive Predictive Value,Negative Predictive Values, Precision & Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bcd0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate False Postive Rate - predicting conversion when customer does not have convert\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e151c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive predictive value \n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the confusion matrix again\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_Predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Precision\n",
    "TP / TP + FP\n",
    "\n",
    "confusion[1,1]/(confusion[0,1]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44cefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Recall\n",
    "TP / TP + FN\n",
    "\n",
    "confusion[1,1]/(confusion[1,0]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc2e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_pred_final.Converted , y_train_pred_final.final_Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recall_score(y_train_pred_final.Converted, y_train_pred_final.final_Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c81937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e6c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.Converted, y_train_pred_final.final_Predicted\n",
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Converted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb647b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b586235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling test set\n",
    "\n",
    "num_cols=X_test.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "X_test[num_cols] = scaler.fit_transform(X_test[num_cols])\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e53f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982050df",
   "metadata": {},
   "source": [
    "##### we will do the prediction on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57442cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = res.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cab638",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef711fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_pred to a dataframe which is an array\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69cb2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting CustID to index\n",
    "y_test_df['Prospect ID'] = y_test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing index for both dataframes to append them side by side \n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0423769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending y_test_df and y_pred_1\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9152533",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column \n",
    "y_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3726a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the columns\n",
    "y_pred_final = y_pred_final[['Prospect ID','Converted','Converted_prob']]\n",
    "y_pred_final['Lead_Score'] = y_pred_final.Converted_prob.map( lambda x: round(x*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f56a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head of y_pred_final\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be808543",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final['final_Predicted'] = y_pred_final.Converted_prob.map(lambda x: 1 if x > 0.3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb473b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396fde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_pred_final.Converted, y_pred_final.final_Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_pred_final.Converted, y_pred_final.final_Predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc48e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309992f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_pred_final.Converted , y_pred_final.final_Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_pred_final.Converted, y_pred_final.final_Predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b633d4d3",
   "metadata": {},
   "source": [
    "Observations:\n",
    "    \n",
    "After running the model on the Test Data these are the figures we obtain:\n",
    "    \n",
    "\n",
    "Accuracy : 90.92%\n",
    "    \n",
    "Sensitivity : 91.41%\n",
    "    \n",
    "Specificity : 90.62%\n",
    "    \n",
    "    \n",
    "Final Observation:\n",
    "    \n",
    "comparing the values obtained for Train & Test:\n",
    "    \n",
    "\n",
    "Train Data:\n",
    "    \n",
    "Accuracy : 90.81%\n",
    "\n",
    "Sensitivity : 92.05%\n",
    "\n",
    "Specificity : 90.10%\n",
    "    \n",
    "Test Data: \n",
    "    \n",
    "Accuracy : 90.92%\n",
    "    \n",
    "Sensitivity : 91.41%\n",
    "    \n",
    "Specificity : 90.62%\n",
    "\n",
    "Final conclusion from the logistic regression model:\n",
    "    \n",
    "- The Model seems to predict the Conversion Rate very well and we should be able to give the CEO confidence in making good calls based on this model\n",
    "-  The final model has Sensitivity of 0.91, this means the model is able to predict 91% customers out of all the converted customers, (Positive conversion) correctly.\n",
    "- While we have checked both Sensitivity-Specificity we have considered the for calculating the final prediction.\n",
    "- Accuracy, Sensitivity and Specificity values of test set are around 90%, 91% and 90% which are approximately closer to the respective values calculated using trained set.\n",
    "- Also the lead score calculated in the trained set of data shows the conversion rate on the final predicted model is around 90%\n",
    "- Hence overall this model seems to be good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0308bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1.\tWhich are the top three variables in your model which contribute most towards the probability of a lead getting converted?\n",
    "\n",
    "# From our model we can see that Tags_Lost to EINS, What is your current occupation_Working Professional\n",
    "#Total Time Spent on Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\tWhat are the top 3 categorical/dummy variables in the model which should be focused the most on in order to increase the probability of lead conversion?\n",
    "\n",
    "#Tags_Lost to EINS\n",
    "#Tags_Interested in other courses\n",
    "#Last Activity_Email Bounced\tall these variables has low VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\tX Education has a period of 2 months every year during which they hire some interns. The sales team, in particular, has around 10 interns allotted to them. So during this phase, they wish to make the lead conversion more aggressive. So they want almost all of the potential leads (i.e. the customers who have been predicted as 1 by the model) to be converted and hence, want to make phone calls to as much of such people as possible. Suggest a good strategy they should employ at this stage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.\tSimilarly, at times, the company reaches its target for a quarter before the deadline. During this time, the company wants the sales team to focus on some new work as well. So during this time, the company’s aim is to not make phone calls unless it’s extremely necessary, i.e. they want to minimize the rate of useless phone calls. Suggest a strategy they should employ at this stage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c24e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
